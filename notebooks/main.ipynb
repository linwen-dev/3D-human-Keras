{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-05T15:35:19.866893",
     "start_time": "2016-11-05T15:35:19.861686"
    },
    "collapsed": false
   },
   "source": [
    "Where I try to make a variational auto encoder (VAE) that fits makehuman data.\n",
    "\n",
    "Goal: find if it's faster and takes less memory to use a fitted model, that the normal morphtargets. The morphtargets are linear interp so probobly not but we will see. There may also be additional side effects to this, and I could ask humans to classify the models to possibly get more accurate labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:18:14.100296",
     "start_time": "2016-11-18T13:18:12.001648"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5408009d3d7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown backend: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BACKEND\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named tensorflow"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import keras\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data\n",
    "\n",
    "The consistent of:\n",
    "- X the delta on each vertice (base vertices as in basemodel.json)\n",
    "- y: the parameters used to generate the vertices (param labels are in metadata.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:18:14.254502",
     "start_time": "2016-11-18T13:18:14.103172"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load\n",
    "from path import Path\n",
    "data_path = Path('../data/20161117-193527_None_vae_data')\n",
    "\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "\n",
    "# split into validation data\n",
    "X_train = HDF5Matrix(data_path.joinpath('X_train.hdf5'), 'data')\n",
    "val_indice = int(len(X_train)*0.8)\n",
    "test_indice = int(len(X_train)*0.9)\n",
    "\n",
    "X_train = HDF5Matrix(data_path.joinpath('X_train.hdf5'), 'data', start=0, end=val_indice)\n",
    "y_train = HDF5Matrix(data_path.joinpath('y_train.hdf5'), 'data', start=0, end=val_indice)\n",
    "X_val = HDF5Matrix(data_path.joinpath('X_train.hdf5'), 'data', start=val_indice, end=test_indice)\n",
    "y_val = HDF5Matrix(data_path.joinpath('y_train.hdf5'), 'data', start=val_indice, end=test_indice)\n",
    "X_test = HDF5Matrix(data_path.joinpath('X_train.hdf5'), 'data', start=test_indice, end=None)\n",
    "y_test = HDF5Matrix(data_path.joinpath('y_train.hdf5'), 'data', start=test_indice, end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:18:14.361656",
     "start_time": "2016-11-18T13:18:14.255666"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7903, 19158, 3), (7903, 249), 249)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "metadata = json.load(open(data_path.joinpath('metadata.json')))\n",
    "\n",
    "modifier_names = sorted([(int(k),v) for k,v in metadata['target_dict'].items()])\n",
    "modifier_names = [row[1] for row in modifier_names]\n",
    "\n",
    "X_train.shape, y_train.shape, len(modifier_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:18:14.371289",
     "start_time": "2016-11-18T13:18:14.364931"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_targets = len(modifier_names)\n",
    "nb_vertices = X_train.shape[1]\n",
    "nb_dims = 3\n",
    "hidden_dims = 107*3\n",
    "batch_size = 32\n",
    "nb_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:18:14.564038",
     "start_time": "2016-11-18T13:18:14.553880"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tensorflow wants it to split evenly into nice batch sizes\n",
    "train_crop = X_train.shape[0]%batch_size\n",
    "X_train.end-=train_crop\n",
    "y_train.end-=train_crop\n",
    "\n",
    "val_crop = X_val.shape[0]%batch_size\n",
    "X_val.end-=val_crop\n",
    "y_val.end-=val_crop\n",
    "\n",
    "test_crop = X_test.shape[0]%batch_size\n",
    "X_test.end-=test_crop\n",
    "y_test.end-=test_crop\n",
    "\n",
    "assert X_train.shape[0]%batch_size==0\n",
    "assert y_train.shape[0]%batch_size==0\n",
    "assert X_test.shape[0]%batch_size==0\n",
    "assert y_test.shape[0]%batch_size==0\n",
    "assert X_val.shape[0]%batch_size==0\n",
    "assert y_val.shape[0]%batch_size==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:18:22.636513",
     "start_time": "2016-11-18T13:18:22.626843"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape, InputLayer, Permute, RepeatVector, Dropout, LocallyConnected1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling1D\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:18:34.286388",
     "start_time": "2016-11-18T13:18:34.282416"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import (Input, LocallyConnected1D, ZeroPadding1D, Cropping1D, Embedding, Merge, merge,\n",
    "    Cropping2D, Convolution1D, Convolution2D, Deconvolution2D, BatchNormalization, UpSampling1D, RepeatVector)\n",
    "from keras.layers import embeddings, convolutional, activations, normalization, advanced_activations\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T07:49:48.976359",
     "start_time": "2016-11-18T07:49:48.882600"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input (InputLayer)               (None, 249)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 249)           62250       input[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_4 (LeakyReLU)          (None, 249)           0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 249)           62250       leakyrelu_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_5 (LeakyReLU)          (None, 249)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 57474)         14368500    leakyrelu_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_6 (LeakyReLU)          (None, 57474)         0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "output (Reshape)                 (None, 19158, 3)      0           leakyrelu_6[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 14493000\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# simple 1 layer dense model gives 0.97 acc\n",
    "x = input =  Input((nb_targets,), name='input')\n",
    "\n",
    "x = Dense(nb_targets)(x)\n",
    "x = advanced_activations.LeakyReLU(0.3)(x)\n",
    "\n",
    "x = Dense(nb_targets)(x)\n",
    "x = advanced_activations.LeakyReLU(0.3)(x)\n",
    "\n",
    "x = Dense(nb_vertices*3)(x)\n",
    "x = advanced_activations.LeakyReLU(0.3)(x)\n",
    "\n",
    "x = Reshape((nb_vertices,3),name='output')(x)\n",
    "\n",
    "generator = Model(input,x)\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T07:49:50.582635",
     "start_time": "2016-11-18T07:49:50.578647"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../outputs/20161117-193527_None_vae_data')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = Path('../outputs/'+data_path.name)\n",
    "output_dir.makedirs_p()\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T07:49:51.132991",
     "start_time": "2016-11-18T07:49:51.130592"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arrow\n",
    "ts = arrow.utcnow().format('YYYY-MM-DD_HH-mm-ss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T09:18:31.053138",
     "start_time": "2016-11-18T07:49:51.754782"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7872 samples, validate on 960 samples\n",
      "Epoch 1/200\n",
      "7872/7872 [==============================] - 46s - loss: 0.9615 - acc: 0.4410 - val_loss: 1.2820 - val_acc: 0.4045\n",
      "Epoch 2/200\n",
      "7872/7872 [==============================] - 42s - loss: 0.7160 - acc: 0.6305 - val_loss: 0.8061 - val_acc: 0.5855\n",
      "Epoch 3/200\n",
      "7872/7872 [==============================] - 36s - loss: 0.5571 - acc: 0.7282 - val_loss: 0.5229 - val_acc: 0.7638\n",
      "Epoch 4/200\n",
      "7872/7872 [==============================] - 35s - loss: 0.4935 - acc: 0.7671 - val_loss: 0.4373 - val_acc: 0.8226\n",
      "Epoch 5/200\n",
      "7872/7872 [==============================] - 33s - loss: 0.4507 - acc: 0.7833 - val_loss: 0.4116 - val_acc: 0.8311\n",
      "Epoch 6/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.4237 - acc: 0.7973 - val_loss: 0.5282 - val_acc: 0.7930\n",
      "Epoch 7/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.3770 - acc: 0.8140 - val_loss: 0.3045 - val_acc: 0.8647\n",
      "Epoch 8/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.3432 - acc: 0.8289 - val_loss: 0.3767 - val_acc: 0.8533\n",
      "Epoch 9/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.3074 - acc: 0.8341 - val_loss: 0.2544 - val_acc: 0.8928\n",
      "Epoch 10/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.2896 - acc: 0.8410 - val_loss: 0.2964 - val_acc: 0.8465\n",
      "Epoch 11/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.2726 - acc: 0.8507 - val_loss: 0.3123 - val_acc: 0.8818\n",
      "Epoch 12/200\n",
      "7872/7872 [==============================] - 30s - loss: 0.2568 - acc: 0.8575 - val_loss: 0.2232 - val_acc: 0.8910\n",
      "Epoch 13/200\n",
      "7872/7872 [==============================] - 40s - loss: 0.2418 - acc: 0.8654 - val_loss: 0.2627 - val_acc: 0.8701\n",
      "Epoch 14/200\n",
      "7872/7872 [==============================] - 41s - loss: 0.2394 - acc: 0.8609 - val_loss: 0.3256 - val_acc: 0.8759\n",
      "Epoch 15/200\n",
      "7872/7872 [==============================] - 35s - loss: 0.2284 - acc: 0.8698 - val_loss: 0.2300 - val_acc: 0.8779\n",
      "Epoch 16/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.2235 - acc: 0.8706 - val_loss: 0.2240 - val_acc: 0.8976\n",
      "Epoch 17/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.2120 - acc: 0.8766 - val_loss: 0.2383 - val_acc: 0.8668\n",
      "Epoch 18/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.2112 - acc: 0.8790 - val_loss: 0.2747 - val_acc: 0.8639\n",
      "Epoch 19/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.2002 - acc: 0.8799 - val_loss: 0.2418 - val_acc: 0.9009\n",
      "Epoch 20/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.2004 - acc: 0.8803 - val_loss: 0.2177 - val_acc: 0.8880\n",
      "Epoch 21/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1932 - acc: 0.8852 - val_loss: 0.1963 - val_acc: 0.8961\n",
      "Epoch 22/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1888 - acc: 0.8866 - val_loss: 0.1962 - val_acc: 0.9023\n",
      "Epoch 23/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1887 - acc: 0.8850 - val_loss: 0.2189 - val_acc: 0.9128\n",
      "Epoch 24/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1826 - acc: 0.8886 - val_loss: 0.2493 - val_acc: 0.9069\n",
      "Epoch 25/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1783 - acc: 0.8904 - val_loss: 0.1878 - val_acc: 0.8932\n",
      "Epoch 26/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1755 - acc: 0.8923 - val_loss: 0.1834 - val_acc: 0.9073\n",
      "Epoch 27/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1710 - acc: 0.8947 - val_loss: 0.1972 - val_acc: 0.9049\n",
      "Epoch 28/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1711 - acc: 0.8970 - val_loss: 0.1944 - val_acc: 0.9100\n",
      "Epoch 29/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1653 - acc: 0.8986 - val_loss: 0.1800 - val_acc: 0.9050\n",
      "Epoch 30/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1672 - acc: 0.8966 - val_loss: 0.1863 - val_acc: 0.8949\n",
      "Epoch 31/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1620 - acc: 0.8994 - val_loss: 0.1799 - val_acc: 0.9058\n",
      "Epoch 32/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1585 - acc: 0.9006 - val_loss: 0.2182 - val_acc: 0.8822\n",
      "Epoch 33/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1566 - acc: 0.9014 - val_loss: 0.1943 - val_acc: 0.8962\n",
      "Epoch 34/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1535 - acc: 0.9025 - val_loss: 0.1810 - val_acc: 0.9134\n",
      "Epoch 35/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1518 - acc: 0.9057 - val_loss: 0.2041 - val_acc: 0.9177\n",
      "Epoch 36/200\n",
      "7872/7872 [==============================] - 26s - loss: 0.1477 - acc: 0.9062 - val_loss: 0.1767 - val_acc: 0.9178\n",
      "Epoch 37/200\n",
      "7872/7872 [==============================] - 26s - loss: 0.1501 - acc: 0.9080 - val_loss: 0.1743 - val_acc: 0.9163\n",
      "Epoch 38/200\n",
      "7872/7872 [==============================] - 26s - loss: 0.1485 - acc: 0.9063 - val_loss: 0.1707 - val_acc: 0.9066\n",
      "Epoch 39/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1440 - acc: 0.9071 - val_loss: 0.1697 - val_acc: 0.9099\n",
      "Epoch 40/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1416 - acc: 0.9106 - val_loss: 0.1674 - val_acc: 0.9103\n",
      "Epoch 41/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1386 - acc: 0.9102 - val_loss: 0.2119 - val_acc: 0.9189\n",
      "Epoch 42/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1409 - acc: 0.9093 - val_loss: 0.1920 - val_acc: 0.8930\n",
      "Epoch 43/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1383 - acc: 0.9103 - val_loss: 0.1622 - val_acc: 0.9165\n",
      "Epoch 44/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1351 - acc: 0.9114 - val_loss: 0.1767 - val_acc: 0.9036\n",
      "Epoch 45/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1351 - acc: 0.9134 - val_loss: 0.1718 - val_acc: 0.9211\n",
      "Epoch 46/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1341 - acc: 0.9115 - val_loss: 0.1697 - val_acc: 0.9210\n",
      "Epoch 47/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1308 - acc: 0.9137 - val_loss: 0.1640 - val_acc: 0.9106\n",
      "Epoch 48/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1322 - acc: 0.9148 - val_loss: 0.1695 - val_acc: 0.9157\n",
      "Epoch 49/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1290 - acc: 0.9173 - val_loss: 0.1639 - val_acc: 0.9169\n",
      "Epoch 50/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1303 - acc: 0.9146 - val_loss: 0.1745 - val_acc: 0.9043\n",
      "Epoch 51/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1276 - acc: 0.9146 - val_loss: 0.1645 - val_acc: 0.9120\n",
      "Epoch 52/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1265 - acc: 0.9160 - val_loss: 0.1662 - val_acc: 0.9164\n",
      "Epoch 53/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1247 - acc: 0.9160 - val_loss: 0.1876 - val_acc: 0.9172\n",
      "Epoch 54/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1223 - acc: 0.9195 - val_loss: 0.1599 - val_acc: 0.9164\n",
      "Epoch 55/200\n",
      "7872/7872 [==============================] - 26s - loss: 0.1239 - acc: 0.9199 - val_loss: 0.1563 - val_acc: 0.9192\n",
      "Epoch 56/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1228 - acc: 0.9170 - val_loss: 0.1764 - val_acc: 0.9012\n",
      "Epoch 57/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1202 - acc: 0.9191 - val_loss: 0.1771 - val_acc: 0.9053\n",
      "Epoch 58/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1198 - acc: 0.9207 - val_loss: 0.1767 - val_acc: 0.9220\n",
      "Epoch 59/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1191 - acc: 0.9202 - val_loss: 0.1666 - val_acc: 0.9197\n",
      "Epoch 60/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1177 - acc: 0.9208 - val_loss: 0.1586 - val_acc: 0.9211\n",
      "Epoch 61/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1173 - acc: 0.9210 - val_loss: 0.1716 - val_acc: 0.9269\n",
      "Epoch 62/200\n",
      "7872/7872 [==============================] - 26s - loss: 0.1167 - acc: 0.9203 - val_loss: 0.1553 - val_acc: 0.9219\n",
      "Epoch 63/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1149 - acc: 0.9215 - val_loss: 0.1555 - val_acc: 0.9214\n",
      "Epoch 64/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1149 - acc: 0.9207 - val_loss: 0.1593 - val_acc: 0.9143\n",
      "Epoch 65/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1122 - acc: 0.9229 - val_loss: 0.1970 - val_acc: 0.8972\n",
      "Epoch 66/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1134 - acc: 0.9228 - val_loss: 0.1582 - val_acc: 0.9178\n",
      "Epoch 67/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1127 - acc: 0.9214 - val_loss: 0.1602 - val_acc: 0.9186\n",
      "Epoch 68/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1120 - acc: 0.9232 - val_loss: 0.1593 - val_acc: 0.9129\n",
      "Epoch 69/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1113 - acc: 0.9239 - val_loss: 0.1550 - val_acc: 0.9120\n",
      "Epoch 70/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1115 - acc: 0.9255 - val_loss: 0.1579 - val_acc: 0.9111\n",
      "Epoch 71/200\n",
      "7872/7872 [==============================] - 26s - loss: 0.1089 - acc: 0.9240 - val_loss: 0.1541 - val_acc: 0.9169\n",
      "Epoch 72/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1076 - acc: 0.9263 - val_loss: 0.1582 - val_acc: 0.9153\n",
      "Epoch 73/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1073 - acc: 0.9254 - val_loss: 0.1517 - val_acc: 0.9160\n",
      "Epoch 74/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1083 - acc: 0.9252 - val_loss: 0.1571 - val_acc: 0.9256\n",
      "Epoch 75/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1061 - acc: 0.9265 - val_loss: 0.1596 - val_acc: 0.9259\n",
      "Epoch 76/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1065 - acc: 0.9252 - val_loss: 0.1823 - val_acc: 0.9226\n",
      "Epoch 77/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1067 - acc: 0.9265 - val_loss: 0.1474 - val_acc: 0.9157\n",
      "Epoch 78/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1061 - acc: 0.9246 - val_loss: 0.1674 - val_acc: 0.9220\n",
      "Epoch 79/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1043 - acc: 0.9264 - val_loss: 0.1608 - val_acc: 0.9244\n",
      "Epoch 80/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1053 - acc: 0.9271 - val_loss: 0.1585 - val_acc: 0.9149\n",
      "Epoch 81/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1046 - acc: 0.9264 - val_loss: 0.1589 - val_acc: 0.9192\n",
      "Epoch 82/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1035 - acc: 0.9264 - val_loss: 0.1570 - val_acc: 0.9141\n",
      "Epoch 83/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1023 - acc: 0.9269 - val_loss: 0.1560 - val_acc: 0.9108\n",
      "Epoch 84/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.1017 - acc: 0.9278 - val_loss: 0.1470 - val_acc: 0.9228\n",
      "Epoch 85/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1018 - acc: 0.9290 - val_loss: 0.1765 - val_acc: 0.9064\n",
      "Epoch 86/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1014 - acc: 0.9274 - val_loss: 0.1536 - val_acc: 0.9200\n",
      "Epoch 87/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1004 - acc: 0.9291 - val_loss: 0.1596 - val_acc: 0.9271\n",
      "Epoch 88/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1022 - acc: 0.9271 - val_loss: 0.1616 - val_acc: 0.9133\n",
      "Epoch 89/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1003 - acc: 0.9284 - val_loss: 0.1486 - val_acc: 0.9237\n",
      "Epoch 90/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0998 - acc: 0.9285 - val_loss: 0.1499 - val_acc: 0.9240\n",
      "Epoch 91/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.0982 - acc: 0.9298 - val_loss: 0.1428 - val_acc: 0.9264\n",
      "Epoch 92/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.1002 - acc: 0.9295 - val_loss: 0.1456 - val_acc: 0.9258\n",
      "Epoch 93/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0987 - acc: 0.9305 - val_loss: 0.1449 - val_acc: 0.9205\n",
      "Epoch 94/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0982 - acc: 0.9275 - val_loss: 0.1459 - val_acc: 0.9225\n",
      "Epoch 95/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0970 - acc: 0.9305 - val_loss: 0.1524 - val_acc: 0.9206\n",
      "Epoch 96/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0981 - acc: 0.9296 - val_loss: 0.1444 - val_acc: 0.9261\n",
      "Epoch 97/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0969 - acc: 0.9291 - val_loss: 0.1510 - val_acc: 0.9148\n",
      "Epoch 98/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0960 - acc: 0.9298 - val_loss: 0.1450 - val_acc: 0.9230\n",
      "Epoch 99/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0978 - acc: 0.9306 - val_loss: 0.1504 - val_acc: 0.9178\n",
      "Epoch 100/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0962 - acc: 0.9295 - val_loss: 0.1640 - val_acc: 0.9154\n",
      "Epoch 101/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0954 - acc: 0.9322 - val_loss: 0.1826 - val_acc: 0.9101\n",
      "Epoch 102/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0965 - acc: 0.9310 - val_loss: 0.1434 - val_acc: 0.9247\n",
      "Epoch 103/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.0948 - acc: 0.9311 - val_loss: 0.1411 - val_acc: 0.9268\n",
      "Epoch 104/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0945 - acc: 0.9315 - val_loss: 0.1622 - val_acc: 0.9307\n",
      "Epoch 105/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0952 - acc: 0.9305 - val_loss: 0.1515 - val_acc: 0.9182\n",
      "Epoch 106/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0932 - acc: 0.9323 - val_loss: 0.1751 - val_acc: 0.9082\n",
      "Epoch 107/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0952 - acc: 0.9312 - val_loss: 0.1468 - val_acc: 0.9281\n",
      "Epoch 108/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0948 - acc: 0.9320 - val_loss: 0.1472 - val_acc: 0.9259\n",
      "Epoch 109/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0919 - acc: 0.9335 - val_loss: 0.1483 - val_acc: 0.9255\n",
      "Epoch 110/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0942 - acc: 0.9315 - val_loss: 0.1498 - val_acc: 0.9185\n",
      "Epoch 111/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0926 - acc: 0.9309 - val_loss: 0.1453 - val_acc: 0.9251\n",
      "Epoch 112/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0931 - acc: 0.9303 - val_loss: 0.1439 - val_acc: 0.9278\n",
      "Epoch 113/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0918 - acc: 0.9335 - val_loss: 0.1426 - val_acc: 0.9255\n",
      "Epoch 114/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0939 - acc: 0.9321 - val_loss: 0.1608 - val_acc: 0.9281\n",
      "Epoch 115/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0904 - acc: 0.9337 - val_loss: 0.1515 - val_acc: 0.9190\n",
      "Epoch 116/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0913 - acc: 0.9316 - val_loss: 0.1442 - val_acc: 0.9222\n",
      "Epoch 117/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0916 - acc: 0.9330 - val_loss: 0.1424 - val_acc: 0.9258\n",
      "Epoch 118/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0907 - acc: 0.9337 - val_loss: 0.1552 - val_acc: 0.9194\n",
      "Epoch 119/200\n",
      "7840/7872 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9339\n",
      "Epoch 00118: reducing learning rate to 0.00020000000949949026.\n",
      "7872/7872 [==============================] - 24s - loss: 0.0914 - acc: 0.9339 - val_loss: 0.1479 - val_acc: 0.9197\n",
      "Epoch 120/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.0644 - acc: 0.9504 - val_loss: 0.1320 - val_acc: 0.9314\n",
      "Epoch 121/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.0587 - acc: 0.9529 - val_loss: 0.1313 - val_acc: 0.9318\n",
      "Epoch 122/200\n",
      "7872/7872 [==============================] - 26s - loss: 0.0571 - acc: 0.9535 - val_loss: 0.1311 - val_acc: 0.9316\n",
      "Epoch 123/200\n",
      "7872/7872 [==============================] - 27s - loss: 0.0562 - acc: 0.9538 - val_loss: 0.1309 - val_acc: 0.9326\n",
      "Epoch 124/200\n",
      "7872/7872 [==============================] - 26s - loss: 0.0555 - acc: 0.9540 - val_loss: 0.1321 - val_acc: 0.9334\n",
      "Epoch 125/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0551 - acc: 0.9542 - val_loss: 0.1312 - val_acc: 0.9323\n",
      "Epoch 126/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.0546 - acc: 0.9543 - val_loss: 0.1307 - val_acc: 0.9327\n",
      "Epoch 127/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0542 - acc: 0.9546 - val_loss: 0.1307 - val_acc: 0.9341\n",
      "Epoch 128/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.0538 - acc: 0.9550 - val_loss: 0.1301 - val_acc: 0.9329\n",
      "Epoch 129/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0536 - acc: 0.9549 - val_loss: 0.1307 - val_acc: 0.9311\n",
      "Epoch 130/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0533 - acc: 0.9551 - val_loss: 0.1309 - val_acc: 0.9331\n",
      "Epoch 131/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0530 - acc: 0.9551 - val_loss: 0.1305 - val_acc: 0.9335\n",
      "Epoch 132/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0527 - acc: 0.9553 - val_loss: 0.1312 - val_acc: 0.9336\n",
      "Epoch 133/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0525 - acc: 0.9555 - val_loss: 0.1302 - val_acc: 0.9324\n",
      "Epoch 134/200\n",
      "7872/7872 [==============================] - 29s - loss: 0.0521 - acc: 0.9556 - val_loss: 0.1302 - val_acc: 0.9325\n",
      "Epoch 135/200\n",
      "7872/7872 [==============================] - 29s - loss: 0.0520 - acc: 0.9559 - val_loss: 0.1302 - val_acc: 0.9322\n",
      "Epoch 136/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.0519 - acc: 0.9557 - val_loss: 0.1306 - val_acc: 0.9320\n",
      "Epoch 137/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0515 - acc: 0.9559 - val_loss: 0.1304 - val_acc: 0.9340\n",
      "Epoch 138/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.0512 - acc: 0.9560 - val_loss: 0.1296 - val_acc: 0.9325\n",
      "Epoch 139/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0511 - acc: 0.9561 - val_loss: 0.1301 - val_acc: 0.9322\n",
      "Epoch 140/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0508 - acc: 0.9560 - val_loss: 0.1301 - val_acc: 0.9340\n",
      "Epoch 141/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0506 - acc: 0.9561 - val_loss: 0.1303 - val_acc: 0.9333\n",
      "Epoch 142/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0504 - acc: 0.9564 - val_loss: 0.1297 - val_acc: 0.9344\n",
      "Epoch 143/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0503 - acc: 0.9565 - val_loss: 0.1300 - val_acc: 0.9329\n",
      "Epoch 144/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0502 - acc: 0.9565 - val_loss: 0.1304 - val_acc: 0.9325\n",
      "Epoch 145/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0498 - acc: 0.9566 - val_loss: 0.1298 - val_acc: 0.9321\n",
      "Epoch 146/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0498 - acc: 0.9567 - val_loss: 0.1305 - val_acc: 0.9341\n",
      "Epoch 147/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0496 - acc: 0.9567 - val_loss: 0.1306 - val_acc: 0.9336\n",
      "Epoch 148/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0494 - acc: 0.9568 - val_loss: 0.1302 - val_acc: 0.9328\n",
      "Epoch 149/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0493 - acc: 0.9567 - val_loss: 0.1300 - val_acc: 0.9326\n",
      "Epoch 150/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0491 - acc: 0.9568 - val_loss: 0.1297 - val_acc: 0.9326\n",
      "Epoch 151/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0490 - acc: 0.9568 - val_loss: 0.1300 - val_acc: 0.9335\n",
      "Epoch 152/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0488 - acc: 0.9570 - val_loss: 0.1300 - val_acc: 0.9331\n",
      "Epoch 153/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0487 - acc: 0.9571 - val_loss: 0.1302 - val_acc: 0.9328\n",
      "Epoch 154/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0486 - acc: 0.9572 - val_loss: 0.1304 - val_acc: 0.9334\n",
      "Epoch 155/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0485 - acc: 0.9572 - val_loss: 0.1301 - val_acc: 0.9331\n",
      "Epoch 156/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0483 - acc: 0.9570 - val_loss: 0.1306 - val_acc: 0.9325\n",
      "Epoch 157/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0481 - acc: 0.9573 - val_loss: 0.1302 - val_acc: 0.9343\n",
      "Epoch 158/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0480 - acc: 0.9574 - val_loss: 0.1300 - val_acc: 0.9326\n",
      "Epoch 159/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0480 - acc: 0.9575 - val_loss: 0.1300 - val_acc: 0.9337\n",
      "Epoch 160/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0478 - acc: 0.9575 - val_loss: 0.1307 - val_acc: 0.9342\n",
      "Epoch 161/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0477 - acc: 0.9575 - val_loss: 0.1300 - val_acc: 0.9337\n",
      "Epoch 162/200\n",
      "7872/7872 [==============================] - 25s - loss: 0.0476 - acc: 0.9576 - val_loss: 0.1294 - val_acc: 0.9332\n",
      "Epoch 163/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0476 - acc: 0.9578 - val_loss: 0.1300 - val_acc: 0.9326\n",
      "Epoch 164/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0473 - acc: 0.9577 - val_loss: 0.1301 - val_acc: 0.9332\n",
      "Epoch 165/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0474 - acc: 0.9576 - val_loss: 0.1298 - val_acc: 0.9328\n",
      "Epoch 166/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0472 - acc: 0.9578 - val_loss: 0.1297 - val_acc: 0.9329\n",
      "Epoch 167/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0470 - acc: 0.9577 - val_loss: 0.1299 - val_acc: 0.9339\n",
      "Epoch 168/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0469 - acc: 0.9581 - val_loss: 0.1301 - val_acc: 0.9332\n",
      "Epoch 169/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0469 - acc: 0.9578 - val_loss: 0.1296 - val_acc: 0.9337\n",
      "Epoch 170/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0468 - acc: 0.9581 - val_loss: 0.1296 - val_acc: 0.9336\n",
      "Epoch 171/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0467 - acc: 0.9581 - val_loss: 0.1297 - val_acc: 0.9328\n",
      "Epoch 172/200\n",
      "7872/7872 [==============================] - 55s - loss: 0.0467 - acc: 0.9581 - val_loss: 0.1297 - val_acc: 0.9332\n",
      "Epoch 173/200\n",
      "7872/7872 [==============================] - 59s - loss: 0.0466 - acc: 0.9580 - val_loss: 0.1296 - val_acc: 0.9333\n",
      "Epoch 174/200\n",
      "7872/7872 [==============================] - 40s - loss: 0.0466 - acc: 0.9580 - val_loss: 0.1296 - val_acc: 0.9332\n",
      "Epoch 175/200\n",
      "7872/7872 [==============================] - 37s - loss: 0.0464 - acc: 0.9582 - val_loss: 0.1299 - val_acc: 0.9334\n",
      "Epoch 176/200\n",
      "7872/7872 [==============================] - 37s - loss: 0.0463 - acc: 0.9581 - val_loss: 0.1299 - val_acc: 0.9327\n",
      "Epoch 177/200\n",
      "7872/7872 [==============================] - 37s - loss: 0.0462 - acc: 0.9582 - val_loss: 0.1300 - val_acc: 0.9344\n",
      "Epoch 178/200\n",
      "7872/7872 [==============================] - 39s - loss: 0.0461 - acc: 0.9585 - val_loss: 0.1294 - val_acc: 0.9340\n",
      "Epoch 179/200\n",
      "7872/7872 [==============================] - 43s - loss: 0.0461 - acc: 0.9582 - val_loss: 0.1301 - val_acc: 0.9333\n",
      "Epoch 180/200\n",
      "7872/7872 [==============================] - 40s - loss: 0.0460 - acc: 0.9583 - val_loss: 0.1299 - val_acc: 0.9327\n",
      "Epoch 181/200\n",
      "7872/7872 [==============================] - 39s - loss: 0.0458 - acc: 0.9581 - val_loss: 0.1295 - val_acc: 0.9336\n",
      "Epoch 182/200\n",
      "7872/7872 [==============================] - 39s - loss: 0.0458 - acc: 0.9583 - val_loss: 0.1298 - val_acc: 0.9349\n",
      "Epoch 183/200\n",
      "7872/7872 [==============================] - 37s - loss: 0.0458 - acc: 0.9585 - val_loss: 0.1300 - val_acc: 0.9328\n",
      "Epoch 184/200\n",
      "7872/7872 [==============================] - 35s - loss: 0.0457 - acc: 0.9586 - val_loss: 0.1296 - val_acc: 0.9336\n",
      "Epoch 185/200\n",
      "7840/7872 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9584\n",
      "Epoch 00184: reducing learning rate to 2.0000000949949027e-05.\n",
      "7872/7872 [==============================] - 32s - loss: 0.0458 - acc: 0.9584 - val_loss: 0.1297 - val_acc: 0.9344\n",
      "Epoch 186/200\n",
      "7872/7872 [==============================] - 30s - loss: 0.0434 - acc: 0.9602 - val_loss: 0.1291 - val_acc: 0.9342\n",
      "Epoch 187/200\n",
      "7872/7872 [==============================] - 31s - loss: 0.0431 - acc: 0.9604 - val_loss: 0.1289 - val_acc: 0.9339\n",
      "Epoch 188/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0430 - acc: 0.9604 - val_loss: 0.1290 - val_acc: 0.9338\n",
      "Epoch 189/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0430 - acc: 0.9605 - val_loss: 0.1291 - val_acc: 0.9341\n",
      "Epoch 190/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0429 - acc: 0.9605 - val_loss: 0.1290 - val_acc: 0.9339\n",
      "Epoch 191/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0429 - acc: 0.9605 - val_loss: 0.1291 - val_acc: 0.9340\n",
      "Epoch 192/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0429 - acc: 0.9605 - val_loss: 0.1291 - val_acc: 0.9340\n",
      "Epoch 193/200\n",
      "7840/7872 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9605\n",
      "Epoch 00192: reducing learning rate to 2.0000001313746906e-06.\n",
      "7872/7872 [==============================] - 24s - loss: 0.0429 - acc: 0.9605 - val_loss: 0.1291 - val_acc: 0.9341\n",
      "Epoch 194/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0426 - acc: 0.9607 - val_loss: 0.1290 - val_acc: 0.9340\n",
      "Epoch 195/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0426 - acc: 0.9607 - val_loss: 0.1290 - val_acc: 0.9341\n",
      "Epoch 196/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0426 - acc: 0.9607 - val_loss: 0.1290 - val_acc: 0.9341\n",
      "Epoch 197/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0426 - acc: 0.9608 - val_loss: 0.1290 - val_acc: 0.9340\n",
      "Epoch 198/200\n",
      "7840/7872 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9609\n",
      "Epoch 00197: reducing learning rate to 2.000000222324161e-07.\n",
      "7872/7872 [==============================] - 24s - loss: 0.0426 - acc: 0.9607 - val_loss: 0.1290 - val_acc: 0.9341\n",
      "Epoch 199/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0425 - acc: 0.9608 - val_loss: 0.1290 - val_acc: 0.9341\n",
      "Epoch 200/200\n",
      "7872/7872 [==============================] - 24s - loss: 0.0425 - acc: 0.9608 - val_loss: 0.1290 - val_acc: 0.9340\n"
     ]
    }
   ],
   "source": [
    "# pretrain/test\n",
    "generator.compile(loss='mae',optimizer='nadam', metrics=['accuracy'])\n",
    "history = generator.fit(\n",
    "    y_train,X_train,\n",
    "    verbose=1, nb_epoch=200, batch_size=batch_size,\n",
    "              validation_data=[y_val, X_val], shuffle='batch',\n",
    "              callbacks=[\n",
    "                    keras.callbacks.EarlyStopping(patience=9, monitor='loss'),\n",
    "                    keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=3, verbose=1),\n",
    "                    keras.callbacks.ModelCheckpoint(output_dir.joinpath('model.hdf5'), save_best_only=True),\n",
    "                    keras.callbacks.CSVLogger(output_dir.joinpath('log-%s.log'%ts)),\n",
    "                    keras.callbacks.TensorBoard(log_dir=output_dir),\n",
    "                    \n",
    "\n",
    "                ]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T09:19:02.004511",
     "start_time": "2016-11-18T09:19:01.622772"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAECCAYAAADjBlzIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64845743c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6495f970b8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAECCAYAAADjBlzIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64a4b7d438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(history.history)\n",
    "df[['acc','val_acc']].plot()\n",
    "plt.show()\n",
    "df[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T09:19:16.935331",
     "start_time": "2016-11-18T09:19:14.234755"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 2s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.92633376916249588, 'loss': 0.12936650961637497}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = generator.evaluate(y_test,X_test, verbose=1, batch_size=batch_size)\n",
    "score = dict(zip(generator.metrics_names,score))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T09:19:21.687115",
     "start_time": "2016-11-18T09:19:20.537028"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../outputs/20161117-193527_None_vae_data/model_acc_0.93_date_2016-11-17_23-49-51.hdf')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file=output_dir.joinpath('model_acc_%2.2f_date_%s.hdf'%(score['acc'],ts))\n",
    "generator.save(model_file)\n",
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:35:15.783313",
     "start_time": "2016-11-18T13:35:12.302621"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load old model\n",
    "generator = keras.models.load_model('../outputs/20161117-193527_None_vae_data/model_acc_0.93_date_2016-11-17_23-49-51.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Export model to keras-js\n",
    "https://github.com/transcranial/keras-js\n",
    "\n",
    "to view serve the directory \n",
    "```sh\n",
    "cd ../output/kerasjs_and_threej\n",
    "http-server -o &\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:37:07.010852",
     "start_time": "2016-11-18T13:37:06.699184"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# outputs dir \n",
    "output_dirk = Path('../output/kerasjs_and_threejs/data')\n",
    "output_dirk.makedirs_p()\n",
    "\n",
    "# export weights\n",
    "generator.save_weights(output_dirk.joinpath('model.hdf5'))\n",
    "with open(output_dirk.joinpath('model.json'), 'w') as f:\n",
    "    f.write(generator.to_json())\n",
    "    \n",
    "# also export metadata\n",
    "json.dump(modifier_names,open(output_dirk.joinpath('labels.json'),'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:37:07.744674",
     "start_time": "2016-11-18T13:37:07.082130"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python ../output/kerasjs_and_threejs/node_modules/keras-js/encoder.py ../output/kerasjs_and_threejs/data/model.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-18T13:37:08.364623",
     "start_time": "2016-11-18T13:37:07.746639"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and also export vanilla version\n",
    "output_data = json.load(open(data_path.joinpath('basemodel.json')))\n",
    "output_file = output_dirk.joinpath('human_base.json')\n",
    "json.dump(output_data, open(output_file,'w'), sort_keys=True)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6.0,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}